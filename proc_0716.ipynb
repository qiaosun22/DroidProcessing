{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ae12e0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'droid_raw/1.0.1/AUTOLab/success/2023-07-07/Fri_Jul__7_09:42:23_2023/metadata_AUTOLab+*.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# METADATA_FILE = f'droid_raw/processed_0421/AUTOLab/success/*.json'\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMETADATA_PATTERN\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m     f\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/droid/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'droid_raw/1.0.1/AUTOLab/success/2023-07-07/Fri_Jul__7_09:42:23_2023/metadata_AUTOLab+*.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# METADATA_FILE = f'droid_raw/processed_0421/AUTOLab/success/*.json'\n",
    "\n",
    "with open(METADATA_PATTERN) as f:\n",
    "    f.load()\n",
    "\n",
    "import glob\n",
    "\n",
    "METADATA_PATTERN = 'droid_raw/1.0.1/AUTOLab/success/2023-07-07/Fri_Jul__7_09:42:23_2023/metadata_AUTOLab+*.json'\n",
    "\n",
    "# 获取所有匹配的文件路径\n",
    "metadata_files = glob.glob(METADATA_PATTERN)\n",
    "metadata_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92e22ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing UUID: AUTOLab+44bb9c36+2023-11-25-10h-06m-22s\n",
      "\n",
      "=== Processing ext1 ===\n",
      "Depth shape: (360, 640), range: [218.324, inf]\n",
      "[2025-07-16 14:12:46 UTC][ZED][INFO] Logging level INFO\n",
      "分辨率: 1280 x 720\n",
      "焦距 (fx, fy): 524.3548583984375, 524.3548583984375\n",
      "光心 (cx, cy): 639.7761840820312, 370.2777099609375\n",
      "分辨率: 1280 x 720\n",
      "焦距 (fx, fy): 524.3548583984375, 524.3548583984375\n",
      "光心 (cx, cy): 639.7761840820312, 370.2777099609375\n",
      "[2025-07-16 14:12:46 UTC][ZED][INFO] [Init]  Depth mode: NEURAL\n",
      "[2025-07-16 14:12:46 UTC][ZED][INFO] [Init]  Serial Number: S/N 22008760\n",
      "Z range: 0.2183241993188858, 9.996537208557129\n",
      "Points in camera frame: 160813\n",
      "Colors shape: (160813, 4)\n",
      "Points shape: (160813, 3)\n",
      "✓ Saved colored point cloud: output/2023-11-25/Sat_Nov_25_10:06:22_2023/pointcloud/ext1_pointcloud_0_haoyu.ply (160813 points)\n",
      "\n",
      "=== Processing ext2 ===\n",
      "Depth shape: (360, 640), range: [-inf, inf]\n",
      "[2025-07-16 14:12:46 UTC][ZED][INFO] Logging level INFO\n",
      "分辨率: 1280 x 720\n",
      "焦距 (fx, fy): 531.6160888671875, 531.6160888671875\n",
      "光心 (cx, cy): 636.1516723632812, 344.0093078613281\n",
      "分辨率: 1280 x 720\n",
      "焦距 (fx, fy): 531.6160888671875, 531.6160888671875\n",
      "光心 (cx, cy): 636.1516723632812, 344.0093078613281\n",
      "[2025-07-16 14:12:46 UTC][ZED][INFO] [Init]  Depth mode: NEURAL\n",
      "[2025-07-16 14:12:46 UTC][ZED][INFO] [Init]  Serial Number: S/N 24400334\n",
      "Z range: 0.20746025443077087, 9.998519897460938\n",
      "Points in camera frame: 158671\n",
      "Colors shape: (158671, 4)\n",
      "Points shape: (158671, 3)\n",
      "✓ Saved colored point cloud: output/2023-11-25/Sat_Nov_25_10:06:22_2023/pointcloud/ext2_pointcloud_0_haoyu.ply (158671 points)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import trimesh\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import imageio.v2 as imageio\n",
    "import glob\n",
    "from PIL import Image\n",
    "import glob\n",
    "import h5py\n",
    "import pyzed.sl as sl\n",
    "\n",
    "\n",
    "date = \"2023-11-25\" # \"2023-11-21\" #\"2023-11-24\" #\"2023-11-13\" #\"2023-09-05\"#\"2023-08-12\"#\"2023-10-27\" #\"2023-08-12\" #\"2023-11-30\"\n",
    "timestemp = \"Sat_Nov_25_10:06:22_2023\" #\"Tue_Nov_21_11:23:03_2023\" #\"Tue_Nov_21_08:51:58_2023\" #\"Sat_Nov_25_10:06:22_2023\" #\"Fri_Nov_17_20:30:02_2023\" #\"Fri_Nov_24_18:42:53_2023\" #\"Mon_Nov_13_15:55:29_2023\" #\"Tue_Sep__5_08:50:21_2023\" #\"Fri_Jul__7_14:58:30_2023\" #\"Sat_Aug_12_12:15:52_2023\"#\"Fri_Oct_27_19:49:00_2023\" # #\"Thu_Nov_30_07:37:44_2023\" #\"Fri_Jul__7_09:44:34_2023\" #\"Fri_Jul__7_09:55:14_2023\" #\"Fri_Jul__7_09:44:34_2023\" #\"Fri_Jul__7_09:43:39_2023\" #\"Fri_Jul__7_09:42:23_2023\"\n",
    "camera = \"22008760\"#\"24400334\" #\"22008760\" #\"24400334\"\n",
    "left_or_right = \"right\"\n",
    "file_path = f'droid_raw/1.0.1/AUTOLab/success/{date}/{timestemp}/trajectory.h5'\n",
    "index = 0\n",
    "\n",
    "\n",
    "\n",
    "# --- CONFIG ---\n",
    "CAM_NAMES = ['ext1', 'ext2']\n",
    "\n",
    "# f\"droid_raw/processed_0421/AUTOLab/success/{date}/{timestemp}/frames/{camera_alias}_depth_{index}.npz\"\n",
    "DEPTH_FILES = [\n",
    "    f\"droid_raw/processed_0421/AUTOLab/success/{date}/{timestemp}/frames/{camera_alias}_depth_{index}.npz\" \n",
    "    for camera_alias in CAM_NAMES\n",
    "    # 'data/droid_sample/ext2_depth_0.npz',\n",
    "]\n",
    "\n",
    "# METADATA_FILE = 'droid_raw/processed_0421/AUTOLab/success/metadata_AUTOLab+*.json'\n",
    "INTRINSICS_FILE = 'data/droid_sample/intrinsics.json'\n",
    "CAM2CAM_FILE = 'data/droid_sample/cam2cam.json'\n",
    "\n",
    "\n",
    "RGB_FRAMES_DIR = f\"droid_raw/processed_0421/AUTOLab/success/{date}/{timestemp}/frames/\"#'data/droid_sample/png_frames'\n",
    "\n",
    "METADATA_PATTERN = f'droid_raw/1.0.1/AUTOLab/success/{date}/{timestemp}/metadata_AUTOLab+*.json'\n",
    "# 获取所有匹配的文件路径\n",
    "METADATA_FILE = glob.glob(METADATA_PATTERN)[0]\n",
    "# METADATA_FILE\n",
    "\n",
    "\n",
    "\n",
    "# --- UTILS ---\n",
    "def load_depth(path):\n",
    "    d = np.load(path)\n",
    "    # Try common keys\n",
    "    for k in ['depth', 'arr_0', 'd', 'D']:\n",
    "        if k in d:\n",
    "            return d[k]\n",
    "    # fallback: first array\n",
    "    return list(d.values())[0]\n",
    "\n",
    "def load_rgb_image(cam_serial, frame_idx=0):\n",
    "    \"\"\"Load RGB image for given camera serial and frame index\"\"\"\n",
    "    # Look for RGB images matching the camera serial\n",
    "    camera_alias = cam_serial.replace(\"22008760\", \"ext1\").replace(\"24400334\", \"ext2\")\n",
    "    pattern = os.path.join(RGB_FRAMES_DIR, f\"{camera_alias}_rgb_{index}.png\")#f\"{cam_serial}_*.png\")\n",
    "    rgb_files = sorted(glob.glob(pattern))\n",
    "    \n",
    "    # Use the specified frame index, or the first available frame\n",
    "    if frame_idx < len(rgb_files):\n",
    "        rgb_path = rgb_files[frame_idx]\n",
    "    else:\n",
    "        rgb_path = rgb_files[0]\n",
    "    rgb_img = imageio.imread(rgb_path)\n",
    "    # imageio loads as RGB by default, no need for color conversion\n",
    "    return rgb_img\n",
    "\n",
    "def crop_left_and_resize(rgb_img, depth_shape):\n",
    "    \"\"\"\n",
    "    Crop left half of RGB image and resize to match depth shape\n",
    "    rgb_img: RGB image with shape (H, 2*W, 3)\n",
    "    depth_shape: (H_depth, W_depth) - target shape\n",
    "    \"\"\"\n",
    "    h_rgb, w_rgb, _ = rgb_img.shape\n",
    "    left_img = rgb_img[:, :w_rgb//2, :]\n",
    "    h_depth, w_depth = depth_shape\n",
    "    pil_img = Image.fromarray(left_img)\n",
    "    resized_pil = pil_img.resize((w_depth, h_depth), Image.LANCZOS)\n",
    "    resized_img = np.array(resized_pil)\n",
    "    return resized_img\n",
    "\n",
    "def load_intrinsics(intrinsics_file, uuid, cam_serial):\n",
    "    \"\"\"Load camera intrinsics from intrinsics.json file\"\"\"\n",
    "    with open(intrinsics_file, 'r') as f:\n",
    "        intrinsics_data = json.load(f)\n",
    "    \n",
    "    if uuid not in intrinsics_data:\n",
    "        raise ValueError(f\"UUID {uuid} not found in intrinsics file\")\n",
    "    \n",
    "    if cam_serial not in intrinsics_data[uuid]:\n",
    "        raise ValueError(f\"Camera serial {cam_serial} not found for UUID {uuid}\")\n",
    "    \n",
    "    cam_data = intrinsics_data[uuid][cam_serial]\n",
    "    camera_matrix = cam_data['cameraMatrix']\n",
    "    \n",
    "    # Convert from [fx, cx, fy, cy] format to 3x3 matrix\n",
    "    fx, cx, fy, cy = camera_matrix\n",
    "    K = np.array([\n",
    "        [fx, 0, cx],\n",
    "        [0, fy, cy],\n",
    "        [0,  0,  1],\n",
    "    ])\n",
    "    return K\n",
    "\n",
    "def transform_intrinsics_for_cropped_resized_image(K, original_width, original_height, target_width, target_height):\n",
    "    K_new = K.copy()    \n",
    "    scale_x = target_width / original_width\n",
    "    scale_y = target_height / original_height\n",
    "    K_new[0, 0] *= scale_x\n",
    "    K_new[1, 1] *= scale_y\n",
    "    K_new[0, 2] *= scale_x\n",
    "    K_new[1, 2] *= scale_y\n",
    "    \n",
    "    return K_new\n",
    "\n",
    "def load_cam2cam_transform(cam2cam_file, cam_name):\n",
    "    \"\"\"\n",
    "    Load camera transformation from cam2cam.json\n",
    "    cam_name: 'ext1' (left_cam) or 'ext2' (right_cam)\n",
    "    Returns 4x4 transformation matrix\n",
    "    \"\"\"\n",
    "    with open(cam2cam_file, 'r') as f:\n",
    "        cam2cam_data = json.load(f)\n",
    "    \n",
    "    # Get the first (and likely only) entry\n",
    "    uuid_key = list(cam2cam_data.keys())[0]\n",
    "    data = cam2cam_data[uuid_key]\n",
    "    \n",
    "    if cam_name == 'ext1':\n",
    "        # ext1 is left camera - assume identity transform\n",
    "        pose_matrix = np.array(data['left_cam']['pose'])\n",
    "        return pose_matrix\n",
    "    elif cam_name == 'ext2':\n",
    "        # ext2 is right camera - use its pose from cam2cam\n",
    "        pose_matrix = np.array(data['right_cam']['pose'])\n",
    "        return pose_matrix\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown camera name: {cam_name}\")\n",
    "\n",
    "def depth_to_points_with_colors(depth, rgb_img, K):\n",
    "    \"\"\"Convert depth to 3D points with RGB colors\"\"\"\n",
    "    h, w = depth.shape\n",
    "    i, j = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    \n",
    "    # Filter out invalid depth values early\n",
    "    valid_mask = np.isfinite(depth) & (depth > 100) & (depth < 10000)\n",
    "    \n",
    "    z = depth[valid_mask] / 1000.0\n",
    "    print(f\"Z range: {z.min()}, {z.max()}\")\n",
    "    i_valid = i[valid_mask]\n",
    "    j_valid = j[valid_mask]\n",
    "    \n",
    "    x = (i_valid - K[0,2]) * z / K[0,0]\n",
    "    y = (j_valid - K[1,2]) * z / K[1,1]\n",
    "    pts = np.stack([x, y, z], axis=-1)\n",
    "    \n",
    "    # Extract colors for valid points\n",
    "    colors = rgb_img[j_valid, i_valid]  # Note: j for rows, i for columns\n",
    "    \n",
    "    return pts, colors\n",
    "\n",
    "\n",
    "def to_homogeneous_transform(pose_6d):\n",
    "    \"\"\"\n",
    "    将一个 [x, y, z, rx, ry, rz] 格式的 6-DoF 位姿转换为 4x4 齐次变换矩阵\n",
    "    假设旋转是轴角格式（Axis-angle）\n",
    "    \"\"\"\n",
    "    translation = pose_6d[:3]\n",
    "    rot_vector = pose_6d[3:]\n",
    "\n",
    "    # 使用轴角构造旋转对象\n",
    "    # rotation = R.from_rotvec(rot_vector)\n",
    "\n",
    "    rotation = R.from_euler(\"xyz\", np.array(rot_vector))#.as_matrix()\n",
    "\n",
    "    # 构造 4x4 变换矩阵\n",
    "    transform = np.eye(4)\n",
    "    transform[:3, :3] = rotation.as_matrix()\n",
    "    transform[:3, 3] = translation\n",
    "\n",
    "    return transform\n",
    "\n",
    "\n",
    "\n",
    "def get_intrinsic_parameters(svo_filepath, left_or_right = \"left\"):\n",
    "    # 创建 ZED 相机对象\n",
    "    zed = sl.Camera()\n",
    "\n",
    "    # 设置初始化参数\n",
    "    init_params = sl.InitParameters()\n",
    "    init_params.set_from_svo_file(svo_filepath)\n",
    "    init_params.svo_real_time_mode = False  # 不实时播放\n",
    "\n",
    "    # 打开相机\n",
    "    err = zed.open(init_params)\n",
    "    if err != sl.ERROR_CODE.SUCCESS:\n",
    "        # print(\"打开 SVO 文件失败: \", err)\n",
    "        return\n",
    "\n",
    "    # 获取相机信息\n",
    "    camera_info = zed.get_camera_information()\n",
    "    \n",
    "    # print(\"\\n=== 左摄像头内参 ===\")\n",
    "    left_cam_params = camera_info.camera_configuration.calibration_parameters.left_cam\n",
    "    # print(f\"分辨率: {left_cam_params.image_size}\")\n",
    "    resolution = left_cam_params.image_size\n",
    "    print(f\"分辨率: {resolution.width} x {resolution.height}\")\n",
    "    print(f\"焦距 (fx, fy): {left_cam_params.fx}, {left_cam_params.fy}\")\n",
    "    print(f\"光心 (cx, cy): {left_cam_params.cx}, {left_cam_params.cy}\")\n",
    "    # print(f\"畸变系数: {list(left_cam_params.distortion_parameters)}\")\n",
    "\n",
    "    # print(\"\\n=== 右摄像头内参 ===\")\n",
    "    right_cam_params = camera_info.camera_configuration.calibration_parameters.right_cam\n",
    "    # print(f\"分辨率: {right_cam_params.image_size}\")\n",
    "    resolution = left_cam_params.image_size\n",
    "    print(f\"分辨率: {resolution.width} x {resolution.height}\")\n",
    "    print(f\"焦距 (fx, fy): {right_cam_params.fx}, {right_cam_params.fy}\")\n",
    "    print(f\"光心 (cx, cy): {right_cam_params.cx}, {right_cam_params.cy}\")\n",
    "\n",
    "    zed.close()\n",
    "    # return left_cam_params, right_cam_params\n",
    "\n",
    "    if left_or_right == \"left\":\n",
    "        cam_params = left_cam_params\n",
    "    else:\n",
    "        cam_params = right_cam_params\n",
    "\n",
    "    fx, fy = cam_params.fx, cam_params.fy\n",
    "    cx, cy = cam_params.cx, cam_params.cy\n",
    "\n",
    "\n",
    "    fx /= 2\n",
    "    fy /= 2\n",
    "    cx /= 2\n",
    "    cy /= 2\n",
    "    # Convert from [fx, cx, fy, cy] format to 3x3 matrix\n",
    "    # fx, cx, fy, cy = camera_matrix\n",
    "    K = np.array([\n",
    "        [fx, 0, cx],\n",
    "        [0, fy, cy],\n",
    "        [0,  0,  1],\n",
    "    ])\n",
    "    return K\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open(METADATA_FILE, 'r') as f:\n",
    "        meta = json.load(f)\n",
    "    \n",
    "    uuid = meta['uuid']\n",
    "    print(f\"Processing UUID: {uuid}\")\n",
    "    \n",
    "    # Camera serial mapping\n",
    "    cam_serials = {\n",
    "        'ext1': meta['ext1_cam_serial'],\n",
    "        'ext2': meta['ext2_cam_serial'],\n",
    "        'wrist': meta['wrist_cam_serial']\n",
    "    }\n",
    "    \n",
    "    for cam, depth_file in zip(CAM_NAMES, DEPTH_FILES):\n",
    "        print(f'\\n=== Processing {cam} ===')\n",
    "        \n",
    "        # Check if depth file exists\n",
    "        if not os.path.exists(depth_file):\n",
    "            print(f'Warning: Depth file {depth_file} not found, skipping {cam}')\n",
    "            continue\n",
    "            \n",
    "        depth = load_depth(depth_file)\n",
    "        if depth.ndim == 3:\n",
    "            depth = depth[0]  # take first frame if needed\n",
    "        h, w = depth.shape\n",
    "        print(f\"Depth shape: {depth.shape}, range: [{np.nanmin(depth):.3f}, {np.nanmax(depth):.3f}]\")\n",
    "        \n",
    "        # Load RGB image\n",
    "        cam_serial = cam_serials[cam]\n",
    "        rgb_img = load_rgb_image(cam_serial)\n",
    "        if rgb_img is None:\n",
    "            print(f'Warning: Could not load RGB image for {cam}, skipping camera')\n",
    "            continue\n",
    "        \n",
    "        # Crop left half and resize to match depth\n",
    "        rgb_img = crop_left_and_resize(rgb_img, depth.shape)\n",
    "        \n",
    "        # Load actual camera intrinsics\n",
    "        # K = load_intrinsics(INTRINSICS_FILE, uuid, cam_serial)\n",
    "        svo_filepath = f\"droid_raw/1.0.1/AUTOLab/success/{date}/{timestemp}/recordings/SVO/{cam_serial}.svo\"\n",
    "        K = get_intrinsic_parameters(svo_filepath, left_or_right = \"left\")\n",
    "        \n",
    "        # # Get original image dimensions from intrinsics file\n",
    "        # with open(INTRINSICS_FILE, 'r') as f:\n",
    "        #     intrinsics_data = json.load(f)\n",
    "        # original_width = intrinsics_data[uuid][cam_serial]['width']\n",
    "        # original_height = intrinsics_data[uuid][cam_serial]['height']\n",
    "        \n",
    "        # Transform K to account for cropping left half and resizing to depth dimensions\n",
    "        # target_height, target_width = depth.shape\n",
    "        # K_transformed = transform_intrinsics_for_cropped_resized_image(\n",
    "        #     K, original_width, original_height, target_width, target_height\n",
    "        # )\n",
    "        \n",
    "        # print(f\"Original intrinsics: {K}\")\n",
    "        # print(f\"Original image size: {original_width}x{original_height}\")\n",
    "        # print(f\"Target image size: {target_width}x{target_height}\")\n",
    "        # print(f\"Transformed intrinsics: {K_transformed}\")\n",
    "        # print(f\"Depth shape: {depth.shape}\")\n",
    "        # print(f\"RGB shape: {rgb_img.shape}\")\n",
    "        \n",
    "        # Load camera transformation from cam2cam\n",
    "        # T_cam2world = load_cam2cam_transform(CAM2CAM_FILE, cam)\n",
    "\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            # 获取 action/cartesian_position 数据\n",
    "            # cartesian_pos = f['action/cartesian_position'][()]\n",
    "            camera_extrinsic = f[f'observation/camera_extrinsics/{cam_serial}_{left_or_right}'][()][index]\n",
    "\n",
    "        T_cam2world = to_homogeneous_transform(camera_extrinsic)\n",
    "        \n",
    "        # Convert depth to 3D points in camera frame with colors\n",
    "        K_transformed = K\n",
    "        pts_cam, colors = depth_to_points_with_colors(depth, rgb_img, K_transformed)\n",
    "        \n",
    "        if len(pts_cam) == 0:\n",
    "            print(f'No valid points found for {cam}')\n",
    "            continue\n",
    "        \n",
    "        print(f\"Points in camera frame: {pts_cam.shape[0]}\")\n",
    "        \n",
    "        # Transform points from camera frame to world frame using cam2cam matrix\n",
    "        # Convert to homogeneous coordinates\n",
    "        pts_h = np.concatenate([pts_cam, np.ones((pts_cam.shape[0],1))], axis=1)\n",
    "        \n",
    "        # Apply cam2world transformation: pts_world = T_cam2world @ pts_cam\n",
    "        pts_world = (T_cam2world @ pts_h.T).T[:, :3]\n",
    "        \n",
    "        # Create colored trimesh point cloud\n",
    "        out_path = f\"output/{date}/{timestemp}/pointcloud/{cam}_pointcloud_{index}_haoyu.ply\"\n",
    "        # f\"output/{date}/{timestemp}/pointcloud/combined_pointcloud_{index}_haoyu.ply\"#f'data/droid_sample/{cam}_colored_cloud.ply'\n",
    "        colors = colors.astype(np.float32) / 255.0\n",
    "        print(f\"Colors shape: {colors.shape}\")\n",
    "        print(f\"Points shape: {pts_world.shape}\")\n",
    "        point_cloud = trimesh.PointCloud(vertices=pts_world, colors=colors)\n",
    "        point_cloud.export(out_path)\n",
    "        print(f'✓ Saved colored point cloud: {out_path} ({pts_world.shape[0]} points)')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "droid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
